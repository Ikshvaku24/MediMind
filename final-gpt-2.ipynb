{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-17T16:58:42.514586Z",
     "iopub.status.busy": "2024-11-17T16:58:42.513719Z",
     "iopub.status.idle": "2024-11-17T16:58:42.520943Z",
     "shell.execute_reply": "2024-11-17T16:58:42.520069Z",
     "shell.execute_reply.started": "2024-11-17T16:58:42.514546Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/validation_gpt_data.pkl\n",
      "/kaggle/working/train_gpt_data.pkl\n",
      "/kaggle/working/finalmodel2.pth\n",
      "/kaggle/working/checkpoints/last_epoch.txt\n",
      "/kaggle/working/checkpoints/last_checkpoint/model.safetensors\n",
      "/kaggle/working/checkpoints/last_checkpoint/random_states_0.pkl\n",
      "/kaggle/working/checkpoints/last_checkpoint/optimizer.bin\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/working'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:13:25.924166Z",
     "iopub.status.busy": "2024-11-17T13:13:25.923784Z",
     "iopub.status.idle": "2024-11-17T13:13:26.302868Z",
     "shell.execute_reply": "2024-11-17T13:13:26.302097Z",
     "shell.execute_reply.started": "2024-11-17T13:13:25.924128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:13:35.735491Z",
     "iopub.status.busy": "2024-11-17T13:13:35.735114Z",
     "iopub.status.idle": "2024-11-17T13:13:36.304182Z",
     "shell.execute_reply": "2024-11-17T13:13:36.303210Z",
     "shell.execute_reply.started": "2024-11-17T13:13:35.735445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('/kaggle/input/embeddings/train_embeddings.pkl')\n",
    "val_df = pd.read_pickle('/kaggle/input/embeddings/val_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:13:36.964360Z",
     "iopub.status.busy": "2024-11-17T13:13:36.964020Z",
     "iopub.status.idle": "2024-11-17T13:13:37.016854Z",
     "shell.execute_reply": "2024-11-17T13:13:37.015746Z",
     "shell.execute_reply.started": "2024-11-17T13:13:36.964328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_embeddings</th>\n",
       "      <th>answer_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel sleepy during office hours even after 8...</td>\n",
       "      <td>feeling sleepy during office timing is most co...</td>\n",
       "      <td>[-0.26551718, -0.14716196, -0.31462595, 0.2012...</td>\n",
       "      <td>[-0.20625764, -0.33222866, -0.5742723, 0.17007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>where is the best place to start learning to b...</td>\n",
       "      <td>the web is full of healthyrelated advice which...</td>\n",
       "      <td>[-0.29065245, -0.10290378, -0.55747473, 0.1643...</td>\n",
       "      <td>[-0.19209254, -0.1223455, -0.5607167, 0.143770...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weird rash over body i got a really itchy sens...</td>\n",
       "      <td>lots of things can cause an itchy rash thousan...</td>\n",
       "      <td>[-0.22826323, 0.049277473, -0.46793014, 0.1466...</td>\n",
       "      <td>[-0.26471904, -0.0949292, -0.44640425, 0.16129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>my brother in law accidentlty poked his hand w...</td>\n",
       "      <td>sorry to hear about this it is hard to tell wh...</td>\n",
       "      <td>[-0.19800055, 0.009556178, -0.47398186, 0.2088...</td>\n",
       "      <td>[-0.25098494, -0.13435361, -0.3495351, 0.07525...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>what are the symptoms of pinkeye and is it con...</td>\n",
       "      <td>children under any suspicion of pinkeye will b...</td>\n",
       "      <td>[-0.27357608, -0.08484824, -0.44519228, 0.1813...</td>\n",
       "      <td>[-0.18809138, -0.29502445, -0.5213447, 0.21331...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47596</th>\n",
       "      <td>12 weeks pregnant due jan 20th last period apr...</td>\n",
       "      <td>hi again let us see if this helps you so your ...</td>\n",
       "      <td>[-0.23717599, -0.0022189366, -0.46322224, 0.19...</td>\n",
       "      <td>[-0.31732213, -0.13892588, -0.45899993, 0.1522...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47599</th>\n",
       "      <td>i am starting to turn gray but i am not ready ...</td>\n",
       "      <td>you can use rinses instead of hair dyes or per...</td>\n",
       "      <td>[-0.23984611, -0.04564248, -0.41020805, 0.1701...</td>\n",
       "      <td>[-0.290672, -0.11531881, -0.54826593, 0.162990...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47600</th>\n",
       "      <td>how is hypothyroidism diagnosed</td>\n",
       "      <td>your doctor will ask you about your symptoms a...</td>\n",
       "      <td>[-0.2715611, -0.15185031, -0.34319144, 0.21706...</td>\n",
       "      <td>[-0.21644855, -0.066988036, -0.47266102, 0.200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47601</th>\n",
       "      <td>my teen has anxiety which is controlled by med...</td>\n",
       "      <td>often medications taken over a period of time ...</td>\n",
       "      <td>[-0.17348967, 0.010912182, -0.50446445, 0.1478...</td>\n",
       "      <td>[-0.24016945, -0.12829559, -0.54014903, 0.2128...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47602</th>\n",
       "      <td>how does an overdose of acetaminophen because ...</td>\n",
       "      <td>the answer is that liver damage from acetamino...</td>\n",
       "      <td>[-0.20610282, -0.19793573, -0.44756973, 0.2227...</td>\n",
       "      <td>[-0.17804644, -0.22565675, -0.6042988, 0.19521...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23802 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "4      i feel sleepy during office hours even after 8...   \n",
       "5      where is the best place to start learning to b...   \n",
       "7      weird rash over body i got a really itchy sens...   \n",
       "10     my brother in law accidentlty poked his hand w...   \n",
       "15     what are the symptoms of pinkeye and is it con...   \n",
       "...                                                  ...   \n",
       "47596  12 weeks pregnant due jan 20th last period apr...   \n",
       "47599  i am starting to turn gray but i am not ready ...   \n",
       "47600                    how is hypothyroidism diagnosed   \n",
       "47601  my teen has anxiety which is controlled by med...   \n",
       "47602  how does an overdose of acetaminophen because ...   \n",
       "\n",
       "                                                  answer  \\\n",
       "4      feeling sleepy during office timing is most co...   \n",
       "5      the web is full of healthyrelated advice which...   \n",
       "7      lots of things can cause an itchy rash thousan...   \n",
       "10     sorry to hear about this it is hard to tell wh...   \n",
       "15     children under any suspicion of pinkeye will b...   \n",
       "...                                                  ...   \n",
       "47596  hi again let us see if this helps you so your ...   \n",
       "47599  you can use rinses instead of hair dyes or per...   \n",
       "47600  your doctor will ask you about your symptoms a...   \n",
       "47601  often medications taken over a period of time ...   \n",
       "47602  the answer is that liver damage from acetamino...   \n",
       "\n",
       "                                     question_embeddings  \\\n",
       "4      [-0.26551718, -0.14716196, -0.31462595, 0.2012...   \n",
       "5      [-0.29065245, -0.10290378, -0.55747473, 0.1643...   \n",
       "7      [-0.22826323, 0.049277473, -0.46793014, 0.1466...   \n",
       "10     [-0.19800055, 0.009556178, -0.47398186, 0.2088...   \n",
       "15     [-0.27357608, -0.08484824, -0.44519228, 0.1813...   \n",
       "...                                                  ...   \n",
       "47596  [-0.23717599, -0.0022189366, -0.46322224, 0.19...   \n",
       "47599  [-0.23984611, -0.04564248, -0.41020805, 0.1701...   \n",
       "47600  [-0.2715611, -0.15185031, -0.34319144, 0.21706...   \n",
       "47601  [-0.17348967, 0.010912182, -0.50446445, 0.1478...   \n",
       "47602  [-0.20610282, -0.19793573, -0.44756973, 0.2227...   \n",
       "\n",
       "                                       answer_embeddings  \n",
       "4      [-0.20625764, -0.33222866, -0.5742723, 0.17007...  \n",
       "5      [-0.19209254, -0.1223455, -0.5607167, 0.143770...  \n",
       "7      [-0.26471904, -0.0949292, -0.44640425, 0.16129...  \n",
       "10     [-0.25098494, -0.13435361, -0.3495351, 0.07525...  \n",
       "15     [-0.18809138, -0.29502445, -0.5213447, 0.21331...  \n",
       "...                                                  ...  \n",
       "47596  [-0.31732213, -0.13892588, -0.45899993, 0.1522...  \n",
       "47599  [-0.290672, -0.11531881, -0.54826593, 0.162990...  \n",
       "47600  [-0.21644855, -0.066988036, -0.47266102, 0.200...  \n",
       "47601  [-0.24016945, -0.12829559, -0.54014903, 0.2128...  \n",
       "47602  [-0.17804644, -0.22565675, -0.6042988, 0.19521...  \n",
       "\n",
       "[23802 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:13:37.219191Z",
     "iopub.status.busy": "2024-11-17T13:13:37.218769Z",
     "iopub.status.idle": "2024-11-17T13:13:37.257541Z",
     "shell.execute_reply": "2024-11-17T13:13:37.256640Z",
     "shell.execute_reply.started": "2024-11-17T13:13:37.219154Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_embeddings</th>\n",
       "      <th>answer_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why my glucose level drop so much after consum...</td>\n",
       "      <td>pancreatitis can cause insulin derangements in...</td>\n",
       "      <td>[-0.22465815, -0.040735334, -0.43371361, 0.152...</td>\n",
       "      <td>[-0.2187827, -0.07795966, -0.29455113, 0.17727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>does prozac show up on a drug test</td>\n",
       "      <td>not unless the drug test is specifically looki...</td>\n",
       "      <td>[-0.19333406, -0.1531981, -0.46534637, 0.15835...</td>\n",
       "      <td>[-0.27048987, -0.09347108, -0.51278424, 0.1544...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what are the risks in an endarterectomy for wo...</td>\n",
       "      <td>i do believe that you have no other option exc...</td>\n",
       "      <td>[-0.26119143, -0.1005428, -0.45904684, 0.17318...</td>\n",
       "      <td>[-0.22919253, -0.026269164, -0.4260606, 0.1588...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>what does it mean if a food product is labeled...</td>\n",
       "      <td>the fda sets rules for what food manufacturers...</td>\n",
       "      <td>[-0.26061082, -0.022312118, -0.43202183, 0.083...</td>\n",
       "      <td>[-0.19321632, -0.24611172, -0.614113, 0.121839...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>my daughter zones out for 520 seconds often he...</td>\n",
       "      <td>sounds like my historyepilepsy at age 14 compl...</td>\n",
       "      <td>[-0.2818151, 0.010599099, -0.2714289, 0.151786...</td>\n",
       "      <td>[-0.23899251, 0.0012992404, -0.315292, 0.12722...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11890</th>\n",
       "      <td>what are the symptoms of a cataract</td>\n",
       "      <td>the most common symptoms of a cataract are clo...</td>\n",
       "      <td>[-0.29087853, -0.21130046, -0.4244496, 0.20425...</td>\n",
       "      <td>[-0.29276365, -0.18895769, -0.57395875, 0.1902...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11893</th>\n",
       "      <td>my six year old cut himself with rusty nail no...</td>\n",
       "      <td>i do not think it is tetanus unless the wound ...</td>\n",
       "      <td>[-0.1964538, -0.05507811, -0.4414535, 0.191567...</td>\n",
       "      <td>[-0.22308405, -0.026650071, -0.19944909, 0.094...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11894</th>\n",
       "      <td>i had a epidural for pain today in my lumbar i...</td>\n",
       "      <td>hi thanks for the query many a time post epidu...</td>\n",
       "      <td>[-0.23133133, -0.038379483, -0.28095374, 0.153...</td>\n",
       "      <td>[-0.2001123, -0.11215544, -0.32805523, 0.14762...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11898</th>\n",
       "      <td>what to do if you cannot get a diagnosis but c...</td>\n",
       "      <td>you may need a more comprehensive cardiac work...</td>\n",
       "      <td>[-0.24037237, 0.0064388383, -0.44193134, 0.062...</td>\n",
       "      <td>[-0.21089466, -0.03629826, -0.44637397, 0.0968...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11900</th>\n",
       "      <td>is benign prostatic hyperplasia bph a type of ...</td>\n",
       "      <td>no benign prostatic hyperplasia bph is complet...</td>\n",
       "      <td>[-0.23837227, -0.080011405, -0.40485948, 0.243...</td>\n",
       "      <td>[-0.2053136, 0.0019360936, -0.4907298, 0.25377...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5950 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0      why my glucose level drop so much after consum...   \n",
       "4                     does prozac show up on a drug test   \n",
       "7      what are the risks in an endarterectomy for wo...   \n",
       "8      what does it mean if a food product is labeled...   \n",
       "10     my daughter zones out for 520 seconds often he...   \n",
       "...                                                  ...   \n",
       "11890                what are the symptoms of a cataract   \n",
       "11893  my six year old cut himself with rusty nail no...   \n",
       "11894  i had a epidural for pain today in my lumbar i...   \n",
       "11898  what to do if you cannot get a diagnosis but c...   \n",
       "11900  is benign prostatic hyperplasia bph a type of ...   \n",
       "\n",
       "                                                  answer  \\\n",
       "0      pancreatitis can cause insulin derangements in...   \n",
       "4      not unless the drug test is specifically looki...   \n",
       "7      i do believe that you have no other option exc...   \n",
       "8      the fda sets rules for what food manufacturers...   \n",
       "10     sounds like my historyepilepsy at age 14 compl...   \n",
       "...                                                  ...   \n",
       "11890  the most common symptoms of a cataract are clo...   \n",
       "11893  i do not think it is tetanus unless the wound ...   \n",
       "11894  hi thanks for the query many a time post epidu...   \n",
       "11898  you may need a more comprehensive cardiac work...   \n",
       "11900  no benign prostatic hyperplasia bph is complet...   \n",
       "\n",
       "                                     question_embeddings  \\\n",
       "0      [-0.22465815, -0.040735334, -0.43371361, 0.152...   \n",
       "4      [-0.19333406, -0.1531981, -0.46534637, 0.15835...   \n",
       "7      [-0.26119143, -0.1005428, -0.45904684, 0.17318...   \n",
       "8      [-0.26061082, -0.022312118, -0.43202183, 0.083...   \n",
       "10     [-0.2818151, 0.010599099, -0.2714289, 0.151786...   \n",
       "...                                                  ...   \n",
       "11890  [-0.29087853, -0.21130046, -0.4244496, 0.20425...   \n",
       "11893  [-0.1964538, -0.05507811, -0.4414535, 0.191567...   \n",
       "11894  [-0.23133133, -0.038379483, -0.28095374, 0.153...   \n",
       "11898  [-0.24037237, 0.0064388383, -0.44193134, 0.062...   \n",
       "11900  [-0.23837227, -0.080011405, -0.40485948, 0.243...   \n",
       "\n",
       "                                       answer_embeddings  \n",
       "0      [-0.2187827, -0.07795966, -0.29455113, 0.17727...  \n",
       "4      [-0.27048987, -0.09347108, -0.51278424, 0.1544...  \n",
       "7      [-0.22919253, -0.026269164, -0.4260606, 0.1588...  \n",
       "8      [-0.19321632, -0.24611172, -0.614113, 0.121839...  \n",
       "10     [-0.23899251, 0.0012992404, -0.315292, 0.12722...  \n",
       "...                                                  ...  \n",
       "11890  [-0.29276365, -0.18895769, -0.57395875, 0.1902...  \n",
       "11893  [-0.22308405, -0.026650071, -0.19944909, 0.094...  \n",
       "11894  [-0.2001123, -0.11215544, -0.32805523, 0.14762...  \n",
       "11898  [-0.21089466, -0.03629826, -0.44637397, 0.0968...  \n",
       "11900  [-0.2053136, 0.0019360936, -0.4907298, 0.25377...  \n",
       "\n",
       "[5950 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:13:38.372432Z",
     "iopub.status.busy": "2024-11-17T13:13:38.371465Z",
     "iopub.status.idle": "2024-11-17T13:13:38.377433Z",
     "shell.execute_reply": "2024-11-17T13:13:38.376404Z",
     "shell.execute_reply.started": "2024-11-17T13:13:38.372389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load question and answer embeddings from .npy files\n",
    "train_question_embeddings = train_df['question_embeddings']\n",
    "train_answer_embeddings = train_df['answer_embeddings']\n",
    "val_question_embeddings = val_df['question_embeddings']\n",
    "val_answer_embeddings = val_df['answer_embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:13:39.190991Z",
     "iopub.status.busy": "2024-11-17T13:13:39.190643Z",
     "iopub.status.idle": "2024-11-17T13:13:40.020339Z",
     "shell.execute_reply": "2024-11-17T13:13:40.019551Z",
     "shell.execute_reply.started": "2024-11-17T13:13:39.190957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to L2 normalize embeddings\n",
    "def normalize(embedding):\n",
    "    norm = np.linalg.norm(embedding)\n",
    "    return embedding / norm if norm > 0 else embedding\n",
    "\n",
    "# Normalize each embedding\n",
    "train_question_embeddings_norm = np.array([normalize(emb) for emb in train_question_embeddings])\n",
    "train_answer_embeddings_norm = np.array([normalize(emb) for emb in train_answer_embeddings])\n",
    "val_question_embeddings_norm = np.array([normalize(emb) for emb in val_question_embeddings])\n",
    "val_answer_embeddings_norm = np.array([normalize(emb) for emb in val_answer_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:13:40.022050Z",
     "iopub.status.busy": "2024-11-17T13:13:40.021748Z",
     "iopub.status.idle": "2024-11-17T13:13:40.631795Z",
     "shell.execute_reply": "2024-11-17T13:13:40.630890Z",
     "shell.execute_reply.started": "2024-11-17T13:13:40.022017Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create DataFrames for the embeddings\n",
    "train_gpt_data = pd.DataFrame({\n",
    "    'question': train_df['question'].to_list(),\n",
    "    'answer': train_df['answer'].to_list(),\n",
    "    'Q_FFNN_embeds': list(train_question_embeddings_norm),\n",
    "    'A_FFNN_embeds': list(train_answer_embeddings_norm)\n",
    "})\n",
    "\n",
    "val_gpt_data = pd.DataFrame({\n",
    "    'question': val_df['question'].to_list(),\n",
    "    'answer': val_df['answer'].to_list(),\n",
    "    'Q_FFNN_embeds': list(val_question_embeddings_norm),\n",
    "    'A_FFNN_embeds': list(val_answer_embeddings_norm)\n",
    "})\n",
    "\n",
    "# Save the processed training and validation data to disk\n",
    "train_gpt_data.to_pickle('./train_gpt_data.pkl')\n",
    "val_gpt_data.to_pickle('./validation_gpt_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:13:40.633560Z",
     "iopub.status.busy": "2024-11-17T13:13:40.633275Z",
     "iopub.status.idle": "2024-11-17T13:13:41.104096Z",
     "shell.execute_reply": "2024-11-17T13:13:41.103262Z",
     "shell.execute_reply.started": "2024-11-17T13:13:40.633529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load processed embeddings\n",
    "train_gpt_data = pd.read_pickle(\"./train_gpt_data.pkl\")\n",
    "validation_gpt_data = pd.read_pickle(\"./validation_gpt_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:13:41.108502Z",
     "iopub.status.busy": "2024-11-17T13:13:41.108211Z",
     "iopub.status.idle": "2024-11-17T13:13:41.147817Z",
     "shell.execute_reply": "2024-11-17T13:13:41.146904Z",
     "shell.execute_reply.started": "2024-11-17T13:13:41.108471Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Q_FFNN_embeds</th>\n",
       "      <th>A_FFNN_embeds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel sleepy during office hours even after 8...</td>\n",
       "      <td>feeling sleepy during office timing is most co...</td>\n",
       "      <td>[-0.015292753, -0.008475955, -0.018121228, 0.0...</td>\n",
       "      <td>[-0.012246236, -0.019725576, -0.03409655, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>where is the best place to start learning to b...</td>\n",
       "      <td>the web is full of healthyrelated advice which...</td>\n",
       "      <td>[-0.017639488, -0.0062451563, -0.03383274, 0.0...</td>\n",
       "      <td>[-0.011490919, -0.007318672, -0.033541907, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weird rash over body i got a really itchy sens...</td>\n",
       "      <td>lots of things can cause an itchy rash thousan...</td>\n",
       "      <td>[-0.013287391, 0.0028684824, -0.027238598, 0.0...</td>\n",
       "      <td>[-0.01591705, -0.005707911, -0.026841434, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my brother in law accidentlty poked his hand w...</td>\n",
       "      <td>sorry to hear about this it is hard to tell wh...</td>\n",
       "      <td>[-0.0117288185, 0.0005660726, -0.028076928, 0....</td>\n",
       "      <td>[-0.014676283, -0.0078562945, -0.02043898, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are the symptoms of pinkeye and is it con...</td>\n",
       "      <td>children under any suspicion of pinkeye will b...</td>\n",
       "      <td>[-0.016663516, -0.005168105, -0.027116654, 0.0...</td>\n",
       "      <td>[-0.011119753, -0.017441519, -0.03082132, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23797</th>\n",
       "      <td>12 weeks pregnant due jan 20th last period apr...</td>\n",
       "      <td>hi again let us see if this helps you so your ...</td>\n",
       "      <td>[-0.013904416, -0.00013008491, -0.027156351, 0...</td>\n",
       "      <td>[-0.018717567, -0.008194683, -0.027074574, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23798</th>\n",
       "      <td>i am starting to turn gray but i am not ready ...</td>\n",
       "      <td>you can use rinses instead of hair dyes or per...</td>\n",
       "      <td>[-0.014035215, -0.0026708876, -0.024004383, 0....</td>\n",
       "      <td>[-0.017434262, -0.006916725, -0.032884527, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23799</th>\n",
       "      <td>how is hypothyroidism diagnosed</td>\n",
       "      <td>your doctor will ask you about your symptoms a...</td>\n",
       "      <td>[-0.015845068, -0.008860174, -0.02002456, 0.01...</td>\n",
       "      <td>[-0.012838074, -0.0039732186, -0.02803464, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23800</th>\n",
       "      <td>my teen has anxiety which is controlled by med...</td>\n",
       "      <td>often medications taken over a period of time ...</td>\n",
       "      <td>[-0.010499785, 0.0006604172, -0.03053074, 0.00...</td>\n",
       "      <td>[-0.014414711, -0.0077001625, -0.03241916, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23801</th>\n",
       "      <td>how does an overdose of acetaminophen because ...</td>\n",
       "      <td>the answer is that liver damage from acetamino...</td>\n",
       "      <td>[-0.012513665, -0.012017795, -0.027174482, 0.0...</td>\n",
       "      <td>[-0.010723441, -0.013590931, -0.03639591, 0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23802 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0      i feel sleepy during office hours even after 8...   \n",
       "1      where is the best place to start learning to b...   \n",
       "2      weird rash over body i got a really itchy sens...   \n",
       "3      my brother in law accidentlty poked his hand w...   \n",
       "4      what are the symptoms of pinkeye and is it con...   \n",
       "...                                                  ...   \n",
       "23797  12 weeks pregnant due jan 20th last period apr...   \n",
       "23798  i am starting to turn gray but i am not ready ...   \n",
       "23799                    how is hypothyroidism diagnosed   \n",
       "23800  my teen has anxiety which is controlled by med...   \n",
       "23801  how does an overdose of acetaminophen because ...   \n",
       "\n",
       "                                                  answer  \\\n",
       "0      feeling sleepy during office timing is most co...   \n",
       "1      the web is full of healthyrelated advice which...   \n",
       "2      lots of things can cause an itchy rash thousan...   \n",
       "3      sorry to hear about this it is hard to tell wh...   \n",
       "4      children under any suspicion of pinkeye will b...   \n",
       "...                                                  ...   \n",
       "23797  hi again let us see if this helps you so your ...   \n",
       "23798  you can use rinses instead of hair dyes or per...   \n",
       "23799  your doctor will ask you about your symptoms a...   \n",
       "23800  often medications taken over a period of time ...   \n",
       "23801  the answer is that liver damage from acetamino...   \n",
       "\n",
       "                                           Q_FFNN_embeds  \\\n",
       "0      [-0.015292753, -0.008475955, -0.018121228, 0.0...   \n",
       "1      [-0.017639488, -0.0062451563, -0.03383274, 0.0...   \n",
       "2      [-0.013287391, 0.0028684824, -0.027238598, 0.0...   \n",
       "3      [-0.0117288185, 0.0005660726, -0.028076928, 0....   \n",
       "4      [-0.016663516, -0.005168105, -0.027116654, 0.0...   \n",
       "...                                                  ...   \n",
       "23797  [-0.013904416, -0.00013008491, -0.027156351, 0...   \n",
       "23798  [-0.014035215, -0.0026708876, -0.024004383, 0....   \n",
       "23799  [-0.015845068, -0.008860174, -0.02002456, 0.01...   \n",
       "23800  [-0.010499785, 0.0006604172, -0.03053074, 0.00...   \n",
       "23801  [-0.012513665, -0.012017795, -0.027174482, 0.0...   \n",
       "\n",
       "                                           A_FFNN_embeds  \n",
       "0      [-0.012246236, -0.019725576, -0.03409655, 0.01...  \n",
       "1      [-0.011490919, -0.007318672, -0.033541907, 0.0...  \n",
       "2      [-0.01591705, -0.005707911, -0.026841434, 0.00...  \n",
       "3      [-0.014676283, -0.0078562945, -0.02043898, 0.0...  \n",
       "4      [-0.011119753, -0.017441519, -0.03082132, 0.01...  \n",
       "...                                                  ...  \n",
       "23797  [-0.018717567, -0.008194683, -0.027074574, 0.0...  \n",
       "23798  [-0.017434262, -0.006916725, -0.032884527, 0.0...  \n",
       "23799  [-0.012838074, -0.0039732186, -0.02803464, 0.0...  \n",
       "23800  [-0.014414711, -0.0077001625, -0.03241916, 0.0...  \n",
       "23801  [-0.010723441, -0.013590931, -0.03639591, 0.01...  \n",
       "\n",
       "[23802 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gpt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "validation_gpt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:13:45.445609Z",
     "iopub.status.busy": "2024-11-17T13:13:45.444861Z",
     "iopub.status.idle": "2024-11-17T13:13:45.629058Z",
     "shell.execute_reply": "2024-11-17T13:13:45.628056Z",
     "shell.execute_reply.started": "2024-11-17T13:13:45.445569Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert embeddings to numpy format for FAISS\n",
    "question_embeddings = np.stack(train_gpt_data['Q_FFNN_embeds'].values).astype('float32')\n",
    "answer_embeddings = np.stack(train_gpt_data['A_FFNN_embeds'].values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:14:06.529732Z",
     "iopub.status.busy": "2024-11-17T13:14:06.528990Z",
     "iopub.status.idle": "2024-11-17T13:14:21.764064Z",
     "shell.execute_reply": "2024-11-17T13:14:21.762909Z",
     "shell.execute_reply.started": "2024-11-17T13:14:06.529694Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-gpu\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-gpu\n",
      "Successfully installed faiss-gpu-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:14:21.766316Z",
     "iopub.status.busy": "2024-11-17T13:14:21.765995Z",
     "iopub.status.idle": "2024-11-17T13:14:22.333498Z",
     "shell.execute_reply": "2024-11-17T13:14:22.332520Z",
     "shell.execute_reply.started": "2024-11-17T13:14:21.766280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "res = faiss.StandardGpuResources()\n",
    "answer_index = faiss.GpuIndexFlatIP(res, answer_embeddings.shape[1])  # Initialize GPU index  # Inner product (cosine similarity)\n",
    "faiss.normalize_L2(answer_embeddings)\n",
    "answer_index.add(answer_embeddings)\n",
    "\n",
    "# # Initialize FAISS index for answer embeddings (cosine similarity)\n",
    "# answer_index = faiss.IndexFlatIP(answer_embeddings.shape[1]) \n",
    "# faiss.normalize_L2(answer_embeddings)\n",
    "# answer_index.add(answer_embeddings)\n",
    "\n",
    "# # Later, if you need to load the index:\n",
    "# cpu_index_loaded = faiss.read_index(\"./answer_index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Save FAISS index to disk (CPU version)\n",
    "# cpu_index = faiss.index_gpu_to_cpu(answer_index)\n",
    "\n",
    "# # Save the CPU index to disk\n",
    "# faiss.write_index(cpu_index, \"./answer_index.faiss\")\n",
    "# # faiss.write_index(answer_index, \"./answer_index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:14:22.493644Z",
     "iopub.status.busy": "2024-11-17T13:14:22.492910Z",
     "iopub.status.idle": "2024-11-17T13:14:28.584462Z",
     "shell.execute_reply": "2024-11-17T13:14:28.583458Z",
     "shell.execute_reply.started": "2024-11-17T13:14:22.493581Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6a440ca89f4e8daa242af8185e253b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907587e799b54b6c8e1e114710e148cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706f323588064af99d40c1f1f47235b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745e369008894f3bbbb265081d34b305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f14c00096f74bb79460ebf31b1b17f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Load tokenizer for GPT-2\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\",use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:19:25.114164Z",
     "iopub.status.busy": "2024-11-17T13:19:25.113755Z",
     "iopub.status.idle": "2024-11-17T13:19:25.123043Z",
     "shell.execute_reply": "2024-11-17T13:19:25.121877Z",
     "shell.execute_reply.started": "2024-11-17T13:19:25.114125Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_gpt_input(question, answer, question_embedding, top_k=20, similarity_threshold=0.8):\n",
    "    # Normalize and search FAISS index\n",
    "    faiss.normalize_L2(np.array([question_embedding]).astype('float32'))\n",
    "    distances, indices = answer_index.search(np.array([question_embedding]), top_k)\n",
    "    \n",
    "    # Filter based on similarity threshold\n",
    "    similar_qas = [\n",
    "        (train_gpt_data.iloc[idx]['question'], train_gpt_data.iloc[idx]['answer'])\n",
    "        for idx, dist in zip(indices[0], distances[0])\n",
    "        if dist >= similarity_threshold\n",
    "    ]\n",
    "    \n",
    "    # Generate context string\n",
    "    context_string = f\"`QUESTION: {question} `ANSWER: {answer}\"\n",
    "    for q, a in similar_qas:\n",
    "        context_string = f\"`QUESTION: {q} `ANSWER: {a} \" + context_string\n",
    "        if len(tokenizer.encode(context_string)) >= 1024:\n",
    "            break\n",
    "    \n",
    "    # Tokenize and truncate\n",
    "    tokenized_input = tokenizer.encode(context_string, truncation=True, max_length=1024)\n",
    "    return tokenized_input[-1024:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:14:28.642619Z",
     "iopub.status.busy": "2024-11-17T13:14:28.641654Z",
     "iopub.status.idle": "2024-11-17T13:14:28.647700Z",
     "shell.execute_reply": "2024-11-17T13:14:28.646841Z",
     "shell.execute_reply.started": "2024-11-17T13:14:28.642568Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'faiss.swigfaiss.GpuIndexFlatIP'>\n"
     ]
    }
   ],
   "source": [
    "print(type(answer_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T13:19:29.023805Z",
     "iopub.status.busy": "2024-11-17T13:19:29.023427Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2976 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      " 19%|█▉        | 579/2976 [05:33<23:13,  1.72it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Batch tokenization to improve efficiency\n",
    "batch_size = 8  # Adjust as needed based on memory capacity\n",
    "def batch_prepare_gpt_input(data, batch_size=batch_size):\n",
    "    tokenized_inputs = []\n",
    "    for i in tqdm(range(0, len(data), batch_size)):\n",
    "        batch = data.iloc[i:i + batch_size]\n",
    "        tokenized_batch = [\n",
    "            prepare_gpt_input(row['question'], row['answer'], row['Q_FFNN_embeds'])\n",
    "            for _, row in batch.iterrows()\n",
    "        ]\n",
    "        tokenized_inputs.extend(tokenized_batch)\n",
    "    return tokenized_inputs\n",
    "\n",
    "train_gpt_data['gpt_input'] = batch_prepare_gpt_input(train_gpt_data, batch_size)\n",
    "validation_gpt_data['gpt_input'] = batch_prepare_gpt_input(validation_gpt_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:48:56.977746Z",
     "iopub.status.busy": "2024-11-17T14:48:56.977383Z",
     "iopub.status.idle": "2024-11-17T14:49:00.373010Z",
     "shell.execute_reply": "2024-11-17T14:49:00.371979Z",
     "shell.execute_reply.started": "2024-11-17T14:48:56.977711Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_gpt_data = pd.read_pickle('./train_gpt_input_data.pkl')\n",
    "validation_gpt_data = pd.read_pickle('./validation_gpt_input_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:49:00.375631Z",
     "iopub.status.busy": "2024-11-17T14:49:00.374775Z",
     "iopub.status.idle": "2024-11-17T14:49:00.438847Z",
     "shell.execute_reply": "2024-11-17T14:49:00.437949Z",
     "shell.execute_reply.started": "2024-11-17T14:49:00.375592Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Q_FFNN_embeds</th>\n",
       "      <th>A_FFNN_embeds</th>\n",
       "      <th>gpt_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel sleepy during office hours even after 8...</td>\n",
       "      <td>feeling sleepy during office timing is most co...</td>\n",
       "      <td>[-0.015292753, -0.008475955, -0.018121228, 0.0...</td>\n",
       "      <td>[-0.012246236, -0.019725576, -0.03409655, 0.01...</td>\n",
       "      <td>[63, 35780, 2849, 25, 329, 262, 1613, 1285, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>where is the best place to start learning to b...</td>\n",
       "      <td>the web is full of healthyrelated advice which...</td>\n",
       "      <td>[-0.017639488, -0.0062451563, -0.03383274, 0.0...</td>\n",
       "      <td>[-0.011490919, -0.007318672, -0.033541907, 0.0...</td>\n",
       "      <td>[63, 35780, 2849, 25, 1312, 373, 1297, 1312, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weird rash over body i got a really itchy sens...</td>\n",
       "      <td>lots of things can cause an itchy rash thousan...</td>\n",
       "      <td>[-0.013287391, 0.0028684824, -0.027238598, 0.0...</td>\n",
       "      <td>[-0.01591705, -0.005707911, -0.026841434, 0.00...</td>\n",
       "      <td>[63, 35780, 2849, 25, 1312, 423, 257, 340, 296...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my brother in law accidentlty poked his hand w...</td>\n",
       "      <td>sorry to hear about this it is hard to tell wh...</td>\n",
       "      <td>[-0.0117288185, 0.0005660726, -0.028076928, 0....</td>\n",
       "      <td>[-0.014676283, -0.0078562945, -0.02043898, 0.0...</td>\n",
       "      <td>[63, 35780, 2849, 25, 616, 11989, 9941, 15881,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are the symptoms of pinkeye and is it con...</td>\n",
       "      <td>children under any suspicion of pinkeye will b...</td>\n",
       "      <td>[-0.016663516, -0.005168105, -0.027116654, 0.0...</td>\n",
       "      <td>[-0.011119753, -0.017441519, -0.03082132, 0.01...</td>\n",
       "      <td>[63, 35780, 2849, 25, 460, 257, 1200, 423, 901...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23797</th>\n",
       "      <td>12 weeks pregnant due jan 20th last period apr...</td>\n",
       "      <td>hi again let us see if this helps you so your ...</td>\n",
       "      <td>[-0.013904416, -0.00013008491, -0.027156351, 0...</td>\n",
       "      <td>[-0.018717567, -0.008194683, -0.027074574, 0.0...</td>\n",
       "      <td>[63, 35780, 2849, 25, 1312, 716, 3058, 9661, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23798</th>\n",
       "      <td>i am starting to turn gray but i am not ready ...</td>\n",
       "      <td>you can use rinses instead of hair dyes or per...</td>\n",
       "      <td>[-0.014035215, -0.0026708876, -0.024004383, 0....</td>\n",
       "      <td>[-0.017434262, -0.006916725, -0.032884527, 0.0...</td>\n",
       "      <td>[63, 35780, 2849, 25, 28107, 7888, 768, 4190, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23799</th>\n",
       "      <td>how is hypothyroidism diagnosed</td>\n",
       "      <td>your doctor will ask you about your symptoms a...</td>\n",
       "      <td>[-0.015845068, -0.008860174, -0.02002456, 0.01...</td>\n",
       "      <td>[-0.012838074, -0.0039732186, -0.02803464, 0.0...</td>\n",
       "      <td>[63, 35780, 2849, 25, 1312, 716, 257, 3261, 42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23800</th>\n",
       "      <td>my teen has anxiety which is controlled by med...</td>\n",
       "      <td>often medications taken over a period of time ...</td>\n",
       "      <td>[-0.010499785, 0.0006604172, -0.03053074, 0.00...</td>\n",
       "      <td>[-0.014414711, -0.0077001625, -0.03241916, 0.0...</td>\n",
       "      <td>[63, 35780, 2849, 25, 318, 340, 1744, 284, 423...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23801</th>\n",
       "      <td>how does an overdose of acetaminophen because ...</td>\n",
       "      <td>the answer is that liver damage from acetamino...</td>\n",
       "      <td>[-0.012513665, -0.012017795, -0.027174482, 0.0...</td>\n",
       "      <td>[-0.010723441, -0.013590931, -0.03639591, 0.01...</td>\n",
       "      <td>[63, 35780, 2849, 25, 616, 4957, 318, 2263, 49...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23802 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0      i feel sleepy during office hours even after 8...   \n",
       "1      where is the best place to start learning to b...   \n",
       "2      weird rash over body i got a really itchy sens...   \n",
       "3      my brother in law accidentlty poked his hand w...   \n",
       "4      what are the symptoms of pinkeye and is it con...   \n",
       "...                                                  ...   \n",
       "23797  12 weeks pregnant due jan 20th last period apr...   \n",
       "23798  i am starting to turn gray but i am not ready ...   \n",
       "23799                    how is hypothyroidism diagnosed   \n",
       "23800  my teen has anxiety which is controlled by med...   \n",
       "23801  how does an overdose of acetaminophen because ...   \n",
       "\n",
       "                                                  answer  \\\n",
       "0      feeling sleepy during office timing is most co...   \n",
       "1      the web is full of healthyrelated advice which...   \n",
       "2      lots of things can cause an itchy rash thousan...   \n",
       "3      sorry to hear about this it is hard to tell wh...   \n",
       "4      children under any suspicion of pinkeye will b...   \n",
       "...                                                  ...   \n",
       "23797  hi again let us see if this helps you so your ...   \n",
       "23798  you can use rinses instead of hair dyes or per...   \n",
       "23799  your doctor will ask you about your symptoms a...   \n",
       "23800  often medications taken over a period of time ...   \n",
       "23801  the answer is that liver damage from acetamino...   \n",
       "\n",
       "                                           Q_FFNN_embeds  \\\n",
       "0      [-0.015292753, -0.008475955, -0.018121228, 0.0...   \n",
       "1      [-0.017639488, -0.0062451563, -0.03383274, 0.0...   \n",
       "2      [-0.013287391, 0.0028684824, -0.027238598, 0.0...   \n",
       "3      [-0.0117288185, 0.0005660726, -0.028076928, 0....   \n",
       "4      [-0.016663516, -0.005168105, -0.027116654, 0.0...   \n",
       "...                                                  ...   \n",
       "23797  [-0.013904416, -0.00013008491, -0.027156351, 0...   \n",
       "23798  [-0.014035215, -0.0026708876, -0.024004383, 0....   \n",
       "23799  [-0.015845068, -0.008860174, -0.02002456, 0.01...   \n",
       "23800  [-0.010499785, 0.0006604172, -0.03053074, 0.00...   \n",
       "23801  [-0.012513665, -0.012017795, -0.027174482, 0.0...   \n",
       "\n",
       "                                           A_FFNN_embeds  \\\n",
       "0      [-0.012246236, -0.019725576, -0.03409655, 0.01...   \n",
       "1      [-0.011490919, -0.007318672, -0.033541907, 0.0...   \n",
       "2      [-0.01591705, -0.005707911, -0.026841434, 0.00...   \n",
       "3      [-0.014676283, -0.0078562945, -0.02043898, 0.0...   \n",
       "4      [-0.011119753, -0.017441519, -0.03082132, 0.01...   \n",
       "...                                                  ...   \n",
       "23797  [-0.018717567, -0.008194683, -0.027074574, 0.0...   \n",
       "23798  [-0.017434262, -0.006916725, -0.032884527, 0.0...   \n",
       "23799  [-0.012838074, -0.0039732186, -0.02803464, 0.0...   \n",
       "23800  [-0.014414711, -0.0077001625, -0.03241916, 0.0...   \n",
       "23801  [-0.010723441, -0.013590931, -0.03639591, 0.01...   \n",
       "\n",
       "                                               gpt_input  \n",
       "0      [63, 35780, 2849, 25, 329, 262, 1613, 1285, 13...  \n",
       "1      [63, 35780, 2849, 25, 1312, 373, 1297, 1312, 7...  \n",
       "2      [63, 35780, 2849, 25, 1312, 423, 257, 340, 296...  \n",
       "3      [63, 35780, 2849, 25, 616, 11989, 9941, 15881,...  \n",
       "4      [63, 35780, 2849, 25, 460, 257, 1200, 423, 901...  \n",
       "...                                                  ...  \n",
       "23797  [63, 35780, 2849, 25, 1312, 716, 3058, 9661, 1...  \n",
       "23798  [63, 35780, 2849, 25, 28107, 7888, 768, 4190, ...  \n",
       "23799  [63, 35780, 2849, 25, 1312, 716, 257, 3261, 42...  \n",
       "23800  [63, 35780, 2849, 25, 318, 340, 1744, 284, 423...  \n",
       "23801  [63, 35780, 2849, 25, 616, 4957, 318, 2263, 49...  \n",
       "\n",
       "[23802 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gpt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:49:00.441012Z",
     "iopub.status.busy": "2024-11-17T14:49:00.440727Z",
     "iopub.status.idle": "2024-11-17T14:49:03.934462Z",
     "shell.execute_reply": "2024-11-17T14:49:03.933621Z",
     "shell.execute_reply.started": "2024-11-17T14:49:00.440981Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, gpt_data, tokenizer, max_length=1024):\n",
    "        self.gpt_data = gpt_data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gpt_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the GPT input (question + answer) for the idx\n",
    "        gpt_input = self.gpt_data['gpt_input'].iloc[idx]\n",
    "        \n",
    "        # Ensure input length is within max_length\n",
    "        tokenized_input = self.tokenizer.encode(gpt_input, truncation=True, padding='max_length', max_length=self.max_length)\n",
    "        \n",
    "        # Calculate mask start index (handle `ANSWER:` position)\n",
    "        mask_start = self.max_length - tokenized_input[::-1].index(self.tokenizer.encode(\"`ANSWER:\")[0]) + 1\n",
    "        loss_mask = [0] * mask_start + [1] * (self.max_length - mask_start)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        input_ids = torch.tensor(tokenized_input, dtype=torch.long)\n",
    "        label = input_ids[1:]  # Shift labels by one position\n",
    "        loss_mask = torch.tensor(loss_mask[:-1], dtype=torch.float32)  # Align mask with labels\n",
    "\n",
    "        return {'input_ids': input_ids, 'labels': label, 'loss_mask': loss_mask}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:49:03.936315Z",
     "iopub.status.busy": "2024-11-17T14:49:03.935844Z",
     "iopub.status.idle": "2024-11-17T14:49:03.942196Z",
     "shell.execute_reply": "2024-11-17T14:49:03.941292Z",
     "shell.execute_reply.started": "2024-11-17T14:49:03.936281Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "    \n",
    "# Define the cross entropy loss with ignore_index set to a non-vocab index, e.g., -1 for masked tokens\n",
    "def masked_loss_fn(logits, labels, mask):\n",
    "    active_logits = logits[mask == 1]\n",
    "    active_labels = labels[mask == 1]\n",
    "     # Check if there are any active elements; otherwise, set a small constant loss\n",
    "    if active_logits.size(0) == 0:\n",
    "        return torch.tensor(0.0, requires_grad=True).to(logits.device)\n",
    "    \n",
    "    return F.cross_entropy(active_logits, active_labels, ignore_index=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:49:03.943922Z",
     "iopub.status.busy": "2024-11-17T14:49:03.943576Z",
     "iopub.status.idle": "2024-11-17T14:49:19.327748Z",
     "shell.execute_reply": "2024-11-17T14:49:19.326770Z",
     "shell.execute_reply.started": "2024-11-17T14:49:03.943882Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=0791ca0cfdde3ed9ceca642760ae5b93e0c1d3aa11b6b0e840d5a55a4d5d478b\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score, evaluate\n",
      "Successfully installed evaluate-0.4.3 rouge-score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:49:19.329570Z",
     "iopub.status.busy": "2024-11-17T14:49:19.329234Z",
     "iopub.status.idle": "2024-11-17T14:49:42.001284Z",
     "shell.execute_reply": "2024-11-17T14:49:42.000326Z",
     "shell.execute_reply.started": "2024-11-17T14:49:19.329534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer  # Needed for the rouge metric\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "perplexity_metric = evaluate.load(\"perplexity\")\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def prepare_dataloader(train_data, val_data, tokenizer, batch_size=4):\n",
    "    train_dataset = GPTDataset(train_data, tokenizer)\n",
    "    validation_dataset = GPTDataset(val_data, tokenizer)\n",
    "    \n",
    "    data_collator = DataCollatorWithPadding(tokenizer, padding='longest')\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=data_collator, pin_memory=True)\n",
    "    validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, collate_fn=data_collator, pin_memory=True)\n",
    "    return train_dataloader, validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:49:42.003079Z",
     "iopub.status.busy": "2024-11-17T14:49:42.002487Z",
     "iopub.status.idle": "2024-11-17T14:49:42.014244Z",
     "shell.execute_reply": "2024-11-17T14:49:42.013246Z",
     "shell.execute_reply.started": "2024-11-17T14:49:42.003036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, accelerator, tokenizer):\n",
    "    model.eval()\n",
    "    eval_loss, correct_predictions, total_predictions = 0, 0, 0\n",
    "    all_predictions, all_labels = [], []\n",
    "    # max_batches = 2 \n",
    "    # for i, batch in enumerate(tqdm(dataloader, desc=\"Evaluating\", leave=False)):\n",
    "    #     if i >= max_batches:\n",
    "    #         break\n",
    "    for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "        with torch.no_grad():\n",
    "            context = batch['input_ids'].to(accelerator.device)\n",
    "            label = batch['labels'].to(accelerator.device)\n",
    "            loss_mask = batch['loss_mask'].to(accelerator.device)\n",
    "\n",
    "            with accelerator.autocast():\n",
    "                outputs = model(context)\n",
    "                logits = outputs.logits[:, :label.size(1), :]\n",
    "                masked_loss = torch.nan_to_num(masked_loss_fn(logits, label, loss_mask))\n",
    "                eval_loss += masked_loss.item()\n",
    "\n",
    "                predictions = torch.argmax(logits, dim=-1)\n",
    "                correct_predictions += ((predictions == label) * loss_mask).sum().item()\n",
    "                total_predictions += loss_mask.sum().item()\n",
    "\n",
    "                # Decode predictions and labels in-place\n",
    "                all_predictions.extend(tokenizer.batch_decode(predictions, skip_special_tokens=True))\n",
    "                all_labels.extend(tokenizer.batch_decode(label, skip_special_tokens=True))\n",
    "\n",
    "\n",
    "    eval_loss /= len(dataloader)\n",
    "    accuracy = (correct_predictions / total_predictions) * 100 if total_predictions > 0 else 0\n",
    "\n",
    "\n",
    "    # Metrics computation\n",
    "    bleu_score = bleu_metric.compute(predictions=all_predictions, references=[[ref] for ref in all_labels])\n",
    "    rouge_score = rouge_metric.compute(predictions=all_predictions, references=[[ref] for ref in all_labels])\n",
    "    perplexity = torch.exp(torch.tensor(eval_loss))\n",
    "        \n",
    "\n",
    "    return eval_loss, accuracy, bleu_score, rouge_score, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:49:42.015819Z",
     "iopub.status.busy": "2024-11-17T14:49:42.015446Z",
     "iopub.status.idle": "2024-11-17T14:49:42.029260Z",
     "shell.execute_reply": "2024-11-17T14:49:42.028497Z",
     "shell.execute_reply.started": "2024-11-17T14:49:42.015787Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# File paths and constants\n",
    "import os\n",
    "CHECKPOINT_DIR = \"./checkpoints2\"\n",
    "MODEL_SAVE_PATH = \"./finalmodel2.pth\"\n",
    "EPOCHS=2\n",
    "BATCH_SIZE=5\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:49:42.033709Z",
     "iopub.status.busy": "2024-11-17T14:49:42.033428Z",
     "iopub.status.idle": "2024-11-17T14:49:42.042623Z",
     "shell.execute_reply": "2024-11-17T14:49:42.041804Z",
     "shell.execute_reply.started": "2024-11-17T14:49:42.033680Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to save the model, optimizer state, and epoch\n",
    "def save_checkpoint(model, optimizer, accelerator, epoch):\n",
    "    accelerator.save_state(os.path.join(CHECKPOINT_DIR, \"last_checkpoint\"))\n",
    "    with open(os.path.join(CHECKPOINT_DIR, \"last_epoch.txt\"), \"w\") as f:\n",
    "        f.write(str(epoch))\n",
    "    print(f\"Checkpoint saved for epoch {epoch + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:49:42.044242Z",
     "iopub.status.busy": "2024-11-17T14:49:42.043819Z",
     "iopub.status.idle": "2024-11-17T14:49:42.053549Z",
     "shell.execute_reply": "2024-11-17T14:49:42.052677Z",
     "shell.execute_reply.started": "2024-11-17T14:49:42.044151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to load a checkpoint if available\n",
    "def load_checkpoint(accelerator):\n",
    "    checkpoint_path = os.path.join(CHECKPOINT_DIR, \"last_checkpoint\")\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        accelerator.load_state(checkpoint_path)\n",
    "        print(f\"Checkpoint loaded from {checkpoint_path}\")\n",
    "        \n",
    "        # Load saved epoch number\n",
    "        with open(os.path.join(CHECKPOINT_DIR, \"last_epoch.txt\"), \"r\") as f:\n",
    "            start_epoch = int(f.read().strip()) + 1\n",
    "            print(\"epoch_loaded\")\n",
    "        return start_epoch\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting from scratch.\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T16:57:46.132883Z",
     "iopub.status.busy": "2024-11-17T16:57:46.132503Z",
     "iopub.status.idle": "2024-11-17T16:57:46.143311Z",
     "shell.execute_reply": "2024-11-17T16:57:46.142450Z",
     "shell.execute_reply.started": "2024-11-17T16:57:46.132845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Main training function\n",
    "def training_pipeline(train_data, val_data, epochs=3, batch_size=4, accumulation_steps=4, lr=2e-5):\n",
    "    accelerator = Accelerator(mixed_precision=\"bf16\")\n",
    "    global tokenizer,model\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model = GPT2LMHeadModel.from_pretrained(\"gpt2\", use_cache=False)\n",
    "    model.to(accelerator.device)\n",
    "\n",
    "    # Prepare datasets and dataloaders\n",
    "    train_dataloader, validation_dataloader = prepare_dataloader(train_data, val_data, tokenizer, batch_size)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    # Prepare with accelerator\n",
    "    model, optimizer, train_dataloader, validation_dataloader = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, validation_dataloader\n",
    "    )\n",
    "\n",
    "    # Attempt to load from the last checkpoint\n",
    "    start_epoch = load_checkpoint(accelerator)\n",
    "\n",
    "    # # Training loop\n",
    "    # for epoch in range(start_epoch, epochs):\n",
    "    #     model.train()\n",
    "    #     total_loss, correct_predictions, total_predictions = 0, 0, 0\n",
    "        \n",
    "    #     with tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\", disable=not accelerator.is_local_main_process) as progress_bar:\n",
    "    #         for i, batch in enumerate(progress_bar):\n",
    "    #             context = batch['input_ids'].to(accelerator.device, non_blocking=True)\n",
    "    #             label = batch['labels'].to(accelerator.device, non_blocking=True)\n",
    "    #             loss_mask = batch['loss_mask'].to(accelerator.device, non_blocking=True)\n",
    "\n",
    "    #             with accelerator.autocast():\n",
    "    #                 outputs = model(context)\n",
    "    #                 logits = outputs.logits[:, :label.size(1), :]\n",
    "    #                 masked_loss = torch.nan_to_num(masked_loss_fn(logits, label, loss_mask))\n",
    "\n",
    "    #             accelerator.backward(masked_loss / accumulation_steps)\n",
    "                \n",
    "    #             if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_dataloader):\n",
    "    #                 optimizer.step()\n",
    "    #                 optimizer.zero_grad()\n",
    "\n",
    "    #             total_loss += masked_loss.item() / accumulation_steps\n",
    "    #             predictions = torch.argmax(logits, dim=-1)\n",
    "    #             correct_predictions += ((predictions == label) * loss_mask).sum().item()\n",
    "    #             total_predictions += loss_mask.sum().item()\n",
    "                \n",
    "    #             # Update live accuracy and loss in progress bar\n",
    "    #             accuracy = (correct_predictions / total_predictions) * 100 if total_predictions > 0 else 0\n",
    "    #             progress_bar.set_postfix(loss=total_loss / (i + 1), accuracy=accuracy)\n",
    "\n",
    "    #     avg_train_loss = total_loss / len(train_dataloader)\n",
    "    #     train_accuracy = (correct_predictions / total_predictions) * 100 if total_predictions > 0 else 0\n",
    "    #     print(f\"Epoch {epoch + 1} Training Loss: {avg_train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    #     # Save checkpoint at the end of each epoch\n",
    "    #     save_checkpoint(model, optimizer, accelerator, epoch)\n",
    "        \n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_accuracy, bleu_score, rouge_score, perplexity = evaluate_model(model, validation_dataloader, accelerator, tokenizer)\n",
    "    # Extract the main BLEU and ROUGE scores from dictionaries\n",
    "    # bleu_main_score = bleu_score['bleu']\n",
    "    rouge1 = rouge_score['rouge1']\n",
    "    rouge2 = rouge_score['rouge2']\n",
    "    rougeL = rouge_score['rougeL']\n",
    "    \n",
    "    # Print formatted output for the main scores\n",
    "    print(f\"Epoch Validation Loss: {val_loss:.4f}, \"\n",
    "        f\"Validation Accuracy: {val_accuracy:.2f}%, \"\n",
    "        #   f\"BLEU Score: {bleu_main_score:.4f}, \"\n",
    "        f\"ROUGE-1: {rouge1:.4f}, \"\n",
    "        f\"ROUGE-2: {rouge2:.4f}, \"\n",
    "        f\"ROUGE-L: {rougeL:.4f}, \"\n",
    "        f\"Perplexity: {perplexity:.4f}\")\n",
    "    print(\"bleu score \",bleu_score)\n",
    "        \n",
    "\n",
    "    # # Final model save\n",
    "    # accelerator.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    # print(\"Training completed, and model saved at final location.\")\n",
    "    # Return the model and tokenizer for evaluation\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T16:57:48.017906Z",
     "iopub.status.busy": "2024-11-17T16:57:48.017552Z",
     "iopub.status.idle": "2024-11-17T16:57:50.967916Z",
     "shell.execute_reply": "2024-11-17T16:57:50.966900Z",
     "shell.execute_reply.started": "2024-11-17T16:57:48.017875Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on one GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ikshvaku Rastogi\\Documents\\Documents\\Minor Project\\New folder\\temp2\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from ./checkpoints2\\last_checkpoint\n",
      "epoch_loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Validation Loss: 1.1254, Validation Accuracy: 76.92%, ROUGE-1: 0.8287, ROUGE-2: 0.6480, ROUGE-L: 0.7433, Perplexity: 3.0814\n",
      "bleu score  {'bleu': 0.648246196430173, 'precisions': [0.837145829290844, 0.6611913224446131, 0.5885792274720839, 0.5485752122691898], 'brevity_penalty': 0.9970056830457246, 'length_ratio': 0.9970101570771565, 'translation_length': 5395809, 'reference_length': 5411990}\n"
     ]
    }
   ],
   "source": [
    "from accelerate import notebook_launcher\n",
    "# Run the training pipeline (adjust arguments as needed)\n",
    "notebook_launcher(training_pipeline, args=(train_gpt_data, validation_gpt_data,EPOCHS,BATCH_SIZE), num_processes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T17:00:36.494528Z",
     "iopub.status.busy": "2024-11-17T17:00:36.494141Z",
     "iopub.status.idle": "2024-11-17T17:00:36.502091Z",
     "shell.execute_reply": "2024-11-17T17:00:36.501156Z",
     "shell.execute_reply.started": "2024-11-17T17:00:36.494492Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T17:21:44.344728Z",
     "iopub.status.busy": "2024-11-17T17:21:44.344129Z",
     "iopub.status.idle": "2024-11-17T17:21:44.349067Z",
     "shell.execute_reply": "2024-11-17T17:21:44.347985Z",
     "shell.execute_reply.started": "2024-11-17T17:21:44.344691Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader, validation_dataloader = prepare_dataloader(train_gpt_data, validation_gpt_data, tokenizer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T18:08:09.463546Z",
     "iopub.status.busy": "2024-11-17T18:08:09.462826Z",
     "iopub.status.idle": "2024-11-17T18:08:09.469184Z",
     "shell.execute_reply": "2024-11-17T18:08:09.468291Z",
     "shell.execute_reply.started": "2024-11-17T18:08:09.463505Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='checkpoints2.zip' target='_blank'>checkpoints2.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/checkpoints2.zip"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'checkpoints2.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T18:06:15.672489Z",
     "iopub.status.busy": "2024-11-17T18:06:15.672140Z",
     "iopub.status.idle": "2024-11-17T18:07:35.624094Z",
     "shell.execute_reply": "2024-11-17T18:07:35.623180Z",
     "shell.execute_reply.started": "2024-11-17T18:06:15.672459Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/checkpoints2.zip'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.make_archive('checkpoints2','zip','checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Ikshvaku Rastogi\\AppData\\Local\\Temp\\ipykernel_9184\\1292321941.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BioBERT model weights loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ikshvaku Rastogi\\Documents\\Documents\\Minor Project\\New folder\\temp2\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ikshvaku Rastogi\\AppData\\Local\\Temp\\ipykernel_9184\\1292321941.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  gpt2_checkpoint = torch.load(gpt2_checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 model weights loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, GPT2Tokenizer, GPT2LMHeadModel\n",
    "import faiss\n",
    "from transformers import AutoModelForSequenceClassification,BertTokenizer\n",
    "# Load BioBERT tokenizer and model\n",
    "biobert_tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.2\")\n",
    "biobert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"dmis-lab/biobert-base-cased-v1.2\",\n",
    "    num_labels=1\n",
    ")\n",
    "\n",
    "biobert_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Load BioBERT weights from checkpoint\n",
    "try:\n",
    "    checkpoint_path = \"./biobert/checkpoint.pth\"\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    biobert_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(\"BioBERT model weights loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading BioBERT checkpoint: {e}\")\n",
    "\n",
    "# Load GPT-2 tokenizer and model\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token  # Set pad token to eos_token\n",
    "\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")  # Load base GPT-2 model\n",
    "gpt2_model.eval()  # Set model to evaluation mode\n",
    "# Ensure the model is on GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "biobert_model = biobert_model.to(device)\n",
    "gpt2_model = gpt2_model.to(device)\n",
    "\n",
    "# Load GPT-2 weights from checkpoint\n",
    "try:\n",
    "    gpt2_checkpoint_path = \"./finalmodel2.pth\"\n",
    "    gpt2_checkpoint = torch.load(gpt2_checkpoint_path)\n",
    "    gpt2_model.load_state_dict(gpt2_checkpoint)\n",
    "    print(\"GPT-2 model weights loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading GPT-2 checkpoint: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_index = faiss.read_index('./answer_index.faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_gpt_data = pd.read_pickle('./train_gpt_input_data.pkl')\n",
    "validation_gpt_data = pd.read_pickle('./validation_gpt_input_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_gpt_input(question, question_embedding, tokenizer , top_k=20, similarity_threshold=0.8):\n",
    "    # Normalize and search FAISS index\n",
    "    faiss.normalize_L2(np.array([question_embedding]).astype('float32'))\n",
    "    distances, indices = answer_index.search(np.array([question_embedding]), top_k)\n",
    "    \n",
    "    # Filter based on similarity threshold\n",
    "    similar_qas = [\n",
    "        (train_gpt_data.iloc[idx]['question'], train_gpt_data.iloc[idx]['answer'])\n",
    "        for idx, dist in zip(indices[0], distances[0])\n",
    "        if dist >= similarity_threshold\n",
    "    ]\n",
    "    \n",
    "    # Generate context string\n",
    "    seen_questions = set()\n",
    "    context_string = f\"`QUESTION: {question} `ANSWER:\"\n",
    "\n",
    "    # Limit number of questions in context\n",
    "    max_questions_in_context = 5  # Adjust this number based on how much context you want to provide\n",
    "\n",
    "    for q, a in similar_qas:\n",
    "        if q not in seen_questions:\n",
    "            pair = f\"`QUESTION: {q} `ANSWER: {a} \"\n",
    "            pair = pair.replace(\"\\n\",\"\")\n",
    "            if len(tokenizer.encode(pair + context_string)) < 1024:\n",
    "                context_string = pair + context_string\n",
    "                seen_questions.add(q)\n",
    "            if len(seen_questions) >= max_questions_in_context:\n",
    "                break  # Stop adding more questions after max_questions_in_context\n",
    "\n",
    "    # Tokenize and truncate\n",
    "    tokenized_input = tokenizer.encode(context_string, truncation=True, max_length=1024)\n",
    "    return tokenized_input[-1024:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions,re\n",
    "# Expanding contractions specifically for decontraction handling\n",
    "def decontractions(phrase):\n",
    "    phrase = contractions.fix(phrase).lower()  # Expand contractions\n",
    "    phrase = re.sub(r\"[^\\w\\s]\", \"\", phrase)  # Remove punctuation\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare inputs and extract embeddings\n",
    "def extract_embeddings(text, model, tokenizer, max_length=512):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, padding='max_length', max_length=max_length, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs['input_ids'].to('cuda')\n",
    "    attention_mask = inputs['attention_mask'].to('cuda')\n",
    "    \n",
    "    # Get embeddings from hidden states of the last layer\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        \n",
    "        # Use the last hidden state as sentence embeddings, averaging across tokens\n",
    "        last_hidden_state = outputs.hidden_states[-1]  # Get last layer\n",
    "        embeddings = last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_combine_unique_answers(decoded_output):\n",
    "    # Split the output by \"QUESTION:\" to separate the questions and answers\n",
    "    parts = decoded_output.split(\"`QUESTION: \")\n",
    "    \n",
    "    # Initialize a set to track seen answers and a list to store the unique answers\n",
    "    seen_answers = set()\n",
    "    unique_answers = []\n",
    "\n",
    "    # Iterate through each part starting from the second element (first question part)\n",
    "    for part in parts[1:]:\n",
    "        # Extract answer by splitting on \"ANSWER:\"\n",
    "        if \"`ANSWER:\" in part:\n",
    "            answer_start = part.split(\"`ANSWER: \")[1].strip()  # Get answer text\n",
    "           \n",
    "            if answer_start not in seen_answers:\n",
    "                seen_answers.add(answer_start)\n",
    "                unique_answers.append(answer_start)\n",
    "    \n",
    "    # Combine all unique answers\n",
    "    return \" \".join(unique_answers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Generate answer using the integrated pipeline\n",
    "def generate_answer(question, answer_length=50):\n",
    "    # Preprocess and truncate the input question\n",
    "    preprocessed_question = decontractions(question)\n",
    "    \n",
    "\n",
    "    # Generate BioBERT embeddings\n",
    "    \n",
    "    question_embedding = extract_embeddings(preprocessed_question,biobert_model,biobert_tokenizer)\n",
    "    \n",
    "    # Prepare GPT input using FAISS results\n",
    "    gpt_input = prepare_gpt_input(preprocessed_question, question_embedding, gpt2_tokenizer)\n",
    "    \n",
    "    # Ensure GPT input does not exceed length limit\n",
    "    if len(gpt_input) > (1024 - answer_length):\n",
    "        gpt_input = gpt_input[-(1024 - answer_length):]\n",
    "    \n",
    "    # Generate answer with GPT-2\n",
    "    input_ids = torch.tensor([gpt_input]).to(device)\n",
    "    gpt_output = gpt2_model.generate(input_ids=input_ids, max_length=1024, temperature=0.9, top_k=50, top_p=0.9)\n",
    "    decoded_output = gpt2_tokenizer.decode(gpt_output[0])\n",
    "    \n",
    "    # # Extract and return the generated answer\n",
    "    # answer_start = decoded_output.rindex(\"`ANSWER: \") + len(\"`ANSWER: \")\n",
    "    return decoded_output\n",
    "\n",
    "# Final function for end-to-end pipeline\n",
    "def final_pipeline(question):\n",
    "    # Generate the answer using the GPT-2 model\n",
    "    generated_answer = generate_answer(question)\n",
    "\n",
    "    return extract_and_combine_unique_answers(generated_answer)\n",
    "    \n",
    "    return generated_answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'energy drinks is just one reason for these symptoms anxiety and heart disease are the major reasons whatever be the because meditation and yoga therapy will help settle down the heart rate it can some of the muscles of the neck attach directly to the skull this can cause a muscle tension type headache you are condition can cause you chest pain yes but regarding the pain related to eating where exactly is there any other symptoms respiratory or gastric troubles  back braces will help alot fever is not dangerous it is biologically more protective and therapeutic a lowerthannormal body temperature is often seen in viruses and is of no medical consequence uncontrolled high blood pressure can cause strokes heart failure blindness kidney failure and heart attacks most people with high blood pressure need to take medicines to treat it for their whole lives if the patient is taking a medication that is not helping they should seek medical attention immediately hi this is a knee replacement you need to do a mri on the affected area and a ct scan on the affected area as soon as possible good luck'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipeline(\"what will fix a headache and fever for a patient on blood pressure medicine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'`QUESTION: would a sprained neck induce a headache `ANSWER: it can some of the muscles of the neck attach directly to the skull this can cause a muscle tension type headache `QUESTION: can pain because a fever 49yo male croniccopd gerds cronic pancreatitis arthritis bursitis on a long acting opiot pain reliever drove 325 miles to see dr got home and had 102 fever `ANSWER: no but what is causing the fever could be the because of the pain `QUESTION: what will fix a headache and fever  `ANSWER ? a headache and fever are symptoms of a migraine and a headache and fever are signs of a migraine and a headache and fever `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of intense intense pain that is accompanied by a headache `QUESTION: what is a migraine `ANSWER: a migraine is a feeling of'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'`QUESTION: what are the symptoms of an adult brain tumor `ANSWER: a doctor should be seen if the following symptoms appear frequent headaches vomiting loss of appetite changes in mood and personality changes in ability to think and learn seizures `QUESTION: what are the symptoms of gastroenteritis `ANSWER: does crackers help with nausea `QUESTION: can stress because fevers in toddlers `ANSWER: stress is not considered a because of fever `QUESTION: would a sprained neck induce a headache `ANSWER: it can some of the muscles of the neck attach directly to the skull this can cause a muscle tension type headache `QUESTION: can pain because a fever 49yo male croniccopd gerds cronic pancreatitis arthritis bursitis on a long acting opiot pain reliever drove 325 miles to see dr got home and had 102 fever `ANSWER: no but what is causing the fever could be the because of the pain `QUESTION: what will fix a headache and fever  `ANSWER: a headache and fever are not related symptoms of a migraine `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a migraine nerve pathway pain and swelling `QUESTION: what is a migraine `ANSWER: a migraine is a type of headache that is caused by a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'energy drinks is just one reason for these symptoms anxiety and heart disease are the major reasons whatever be the because meditation and yoga therapy will help settle down the heart rate it can some of the muscles of the neck attach directly to the skull this can cause a muscle tension type headache you are condition can cause you chest pain yes but regarding the pain related to eating where exactly is there any other symptoms respiratory or gastric troubles  back braces will help alot fever is not dangerous it is biologically more protective and therapeutic a lowerthannormal body temperature is often seen in viruses and is of no medical consequence uncontrolled high blood pressure can cause strokes heart failure blindness kidney failure and heart attacks most people with high blood pressure need to take medicines to treat it for their whole lives if the patient is taking a medication that is not helping they should seek medical attention immediately hi this is a knee replacement you need to do a mri on the affected area and a ct scan on the affected area as soon as possible good luck'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i started having pain and burning while urinating a week back',\n",
       "       'is it okay to ride horses while pregnant  i have ridden for years and it is not like i would ride crazy horses or go faster than a walk i know what i am doing and do not see the harm in a slow walk',\n",
       "       'what are the most healthy foods to stock in my refrigerator and freezer',\n",
       "       'how to recover from erectile dysfunction caused by tobacco use  i smoked or chewed my whole adult life there has also been some alcohol abuse as well i am currently 45 and starting 6 months after a vasectomy i had when i was 36 is when i started having problems maintaining and erection for very long and between whatever is wrong with me and the psychological stress of wanting sex but knowing i cannot perform i have quit smoking drinking and using tobacco altogether i have periodontal disease the bone loss is severe i have experimented with viagra fail',\n",
       "       'can i take a anti depressant with my adderall  i have been taking adderall for years now and now have symptoms of stress and or depression i feel like my chest will explode under certain circumstances i am not sure of what i need to do'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gpt_data.sample(5)['question'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6105401,
     "sourceId": 9932154,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6105887,
     "sourceId": 9932763,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "temp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
